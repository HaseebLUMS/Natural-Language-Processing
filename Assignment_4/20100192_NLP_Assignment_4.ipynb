{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "20100192_NLP_Assignment_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lnOXnOxHzFd",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4 CS 5316 Natural Language Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BcDWByA2EHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAXc81hgIHUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip \"/content/drive/My Drive/Colab Notebooks/msr_paraphrase.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3ry-Cr4yFPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# d = \"50\"\n",
        "# !cp \"/content/drive/My Drive/Colab Notebooks/glove_6B/glove.6B.50d.txt\" \"glove.6B.50d.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSAelkozHzFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "# Get the interactive Tools for Matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.style.use('ggplot')\n",
        "from sklearn.decomposition import PCA\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.utils.extmath import randomized_svd\n",
        "from nltk import ngrams\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Activation, RepeatVector,Flatten, TimeDistributed, Input,Bidirectional,LocallyConnected1D,Conv1D,GlobalAveragePooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n",
        "from tensorflow.keras.layers import Embedding, LSTM ,Dropout, SimpleRNN, GRU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# import tensorflow.keras.utils.to_categorical as to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "import math\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai2BH1arHzFr",
        "colab_type": "text"
      },
      "source": [
        "# Final Assingmnet\n",
        "This is going to be the final assignment for deep learning. Here is a very good visual for what you will be doing with\n",
        "<a href=\"https://ibb.co/mh9Ks0j\">deep learning.</a> Lets get started......."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4a4UbaHHzFt",
        "colab_type": "text"
      },
      "source": [
        "# TASK 1 Paraphrase Detection\n",
        "For this task we will be using the [ Microsoft Research Paraphrase Corpus ](https://www.microsoft.com/en-us/download/details.aspx?id=52398). The corpus consist of sentence pairs with 1 or 0 labels which identify if the sentences are paraphrase or not respectively.\n",
        "<br>\n",
        "To perform this task we will be using recurrenct neural network for this task specifically the [LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/). RNN can be architected in multiple ways. Some of the possible ways are as follows:\n",
        "<img src=\"archetecturernn.PNG\">\n",
        "The box in the bottom is the input, followed by the hidden layer (as the middle box), and the box on top is the output layer. The one-to-one architecture is the typical neural network (<i>vanila/Feed Forward</i>) with a hidden layer between the input and the output layer. Example uses of the above archetecture are as follows:\n",
        "<ul>\n",
        "    <li>One-to-many: input is an image and outputs are image captions</li>\n",
        "    <li>Many-to-one: input is a movie's review <i>multiple words in input</i> and output is sentiment associated with the review <i>(we will be using a similar archetecture for our purpose)</i></li>\n",
        "    <li>Many-to-many: machine translation of a sentence in one language to a sentence in another language, POS tagging etc</li>\n",
        "</ul>\n",
        "<br>\n",
        "For this task we will also be using pre-trained word embeddings specificallly <a href=\"https://nlp.stanford.edu/projects/glove/\">(GloVe Embeddings)</a>. Please download the paraphrase <a href=\"https://www.microsoft.com/en-us/download/details.aspx?id=52398\">dataset</a> and glove.6B.zip from <a href=\"https://nlp.stanford.edu/projects/glove/\">here</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9q3zcMUHzFu",
        "colab_type": "text"
      },
      "source": [
        "For this task you are required to implement the following archetecture, please use [keras functional API](https://www.tensorflow.org/guide/keras/functional) :\n",
        "<img src=\"paraphrase.png\">\n",
        "If <a href=\"https://ibb.co/RSSjRM0\">this</a> is you reaction after seeing the model archetecture dont worry we'll explain.\n",
        "The model works as follows, there will be two inputs layers, one for each sentence followed by <b>shared</b> embedding layer which feed thier outputs to the shared LSTM, <b>take the final hidden state output</b> of both LSTM's and concatenate them. Finally feed the concatenated vector to a softmax output layer for classification.\n",
        "<br>\n",
        "<i>(The reason for using one shared embedding and LSTM layer so that the model learns sentence representation for all sentence pairs(x,x') in the dataset. If we were using two seperate LSTMS for x and x' we would need to double the dataset by having both (x,x') and (x',x) pairs so that both LSTM's see the entire train data distribution)</i>\n",
        "The purpose for each layer in the model is as follows:\n",
        "<ul>\n",
        "    <li>Input takes the input sequences and feeds it to the next(you will need to specify the maximum size of a sentence as a parameter of this layer)</li>\n",
        "    <li>Embedding layer, this layer takes the sequence input then for each word in the sequence generates a fixed size vector <i>(word embedding)</i>, this layer can be trained from scratch or can be configured to use pretrained embeddings with or without fine tuning. </li>\n",
        "    <li>LSTM process the embedding vector sequences and at each step generates a hidden state vector(h)and cell memory vector(C)(<i>see diagram</i>), the keras LSTM layer returns three outputs (1) All the hidden states,(2) The final hidden state and (3) The final cell memory state<img src=\"lstm.png\"></li>\n",
        "    <li>The concatenation layer combines multple vectors into a single vector</li>\n",
        "    <li>Finally the output layer predicts if sentence pairs were paraphrase or not</li>\n",
        "</ul>\n",
        "<b>Please refer to the TF-keras documentation for all the layers <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers\">here</a></b>\n",
        "<br><br><br>\n",
        "Now that you understand the theoritical foundation for our approach lets move onto practical implementation.<br>\n",
        "<h3>Data Preperation</h3>\n",
        "\n",
        "<ul>\n",
        "    <li> First we need to preprocess the data, convert the data to lower casing. Any other preprocessing procedures are optional but keep in mind that this will affect the performance of your model.</li>\n",
        "    <li> To make training faster we will fix the maximum sequence length to 20 truncate the longer sequences.</li>\n",
        "    <li> Split the data into test, train and validation in the ratio 20,70,10. Use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">scikit_test_train_split</a> <br><i><b>Hint:</b> use the splitter twice to get desired data splits.</i></li>\n",
        "    <li> Next we need the vocabulary, vocabulary size and to convert sentences to numeric sequences by representing each word with a numeric value which will make our implementation easier later on, use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\">Tokenizer</a> from keras. <br><i>(Fit the tokenizer on train data and use the same tokenizer to convert train,test and validation data to numeric sequences)</i> </li>\n",
        "    <li>  Use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\"> pad sequences</a> to add post padding to all sentences that are shorter than maximum sequence length\n",
        "        <i>(<b>extra info</b>: fit_on_text reserves value/index 0 for padding and assigns numeric value to words starting from index 1)</i></li>\n",
        "</ul>\n",
        "<h3>Loading embeddings</h3>\n",
        "<ul>\n",
        "    <li> To use pretrained embeddings in tf keras embedding layer requires a dictionary, we need to create a dictionary whose keys will be numeric word representations and values will be the embedding vectors.</li>\n",
        "    <li> First step is to load the word embedding pairs from the glove file into a dictionary.</li>\n",
        "    <li> Next we will create a dictionary for our dataset's vocabulary. Copy all the word embeddings for words that are in our vocabulary and in the glove dictionary, if a word exists in our vocabulary but does not exist in glove dictionary create a zero vector of embedding dimension size and add it to the dictionary.</li>\n",
        "</ul>\n",
        "<h3>Create Model</h3>\n",
        "<ul>\n",
        "    <li> Create the model using <a href\"https://www.tensorflow.org/guide/keras/functional\">functional API</a></li>\n",
        "    <li> Hints: The emebedding layer has a parameter that allows you to use pretrained embeddings, for shared layers read the section of shared layer weights in function API docs</li>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em79S8xMHzFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData(fn):\n",
        "    \"\"\"\n",
        "    Return preprocessed data\n",
        "    \n",
        "    Returns: X and Y where X is pair of sentence (x,x') and y is the label 0 or 1\n",
        "    \"\"\"\n",
        "    data = open(fn)\n",
        "    data = np.array([example.split(\"\\t\") for example in data.readlines()])[1:]\n",
        "    data_X = []\n",
        "    data_Y = []\n",
        "    for d in data:\n",
        "      data_X += [(d[3], d[4])]\n",
        "      data_Y += [d[0]]\n",
        "    return data_X, data_Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC1oDxwrHzF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process(sentence):\n",
        "  sentence = sentence.lower().split(\" \")\n",
        "  try:\n",
        "    sentence = sentence[:20]\n",
        "  except: \n",
        "    pass\n",
        "  return \" \".join(sentence)\n",
        "\n",
        "def preprocessing(data):\n",
        "    \"\"\"\n",
        "    Return preprocessed data\n",
        "\n",
        "    Args:\n",
        "        data : sentence pairs\n",
        "    \n",
        "    Returns: preprocessed_data\n",
        "    preprocessed_data : preprocessed dataset \n",
        "    \"\"\"\n",
        "    preprocessed_data = []\n",
        "    for p in data:\n",
        "      preprocessed_data += [(process(p[0]), process(p[1]))]\n",
        "    return preprocessed_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShwDNscCHzF-",
        "colab_type": "text"
      },
      "source": [
        "### Test train split\n",
        "Use test train split from sklearn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhvIYwKaHzF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testTrainSplit(data_X,data_Y):\n",
        "    \"\"\"\n",
        "    Return test train data\n",
        "\n",
        "    Args:\n",
        "        data_X : sentence pairs\n",
        "        data_Y: labels\n",
        "        \n",
        "    Returns: test train and validation split data \n",
        "    \"\"\"\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(data_X, data_Y, test_size=0.1, random_state=0)\n",
        "    return x_train, x_valid, y_train, y_valid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aHLVbI0c7QX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train = loadData('msr_paraphrase_train.txt')\n",
        "x_test, y_test = loadData('msr_paraphrase_test.txt')\n",
        "x_train = preprocessing(x_train)\n",
        "x_test = preprocessing(x_test)\n",
        "x_train, x_valid, y_train, y_valid = testTrainSplit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGxxRZNC9CFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encod = {\n",
        "    \"1\": [0, 1],\n",
        "    \"0\": [1, 0]\n",
        "}\n",
        "y_train_enc = np.array([encod[x] for x in y_train], dtype=np.uint8)\n",
        "y_valid_enc = np.array([encod[x] for x in y_valid], dtype=np.uint8)\n",
        "y_test_enc = np.array([encod[x] for x in y_test], dtype=np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhpNUab1HzGG",
        "colab_type": "text"
      },
      "source": [
        "Implement the step regarding keras Tokenizer in the cell below.<br>\n",
        "<i> Keep in mind that each example is a pair/tupple of sentence(x,x'), combine them into a single sentence so that your data is a list of sentences before calling fit on text(Tokenizer). There is out of vocabulary option in tokenizer check that out aswell.</i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqbD4p9mHzGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get vocabular, vocabulary size and numeric word seqeunces for train,test and validation data\n",
        "tokenizer = Tokenizer(oov_token=\"<unk>\", filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
        "# tokenizer.word_index['<pad>'] = 0\n",
        "# tokenizer.index_word[0] = '<pad>'\n",
        "tmp = [\" \".join(x) for x in x_train]\n",
        "tokenizer.fit_on_texts(tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBqx39IqigsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_vocab(tmp):\n",
        "#   tmp = [\" \".join(x) for x in tmp]\n",
        "#   tmp = \" \".join(tmp).split()\n",
        "#   vocab = list(set(tmp))\n",
        "#   return vocab, len(vocab)\n",
        "# x_train_vocab, x_train_vocab_len = get_vocab(x_train)\n",
        "# x_valid_vocab, x_valid_vocab_len = get_vocab(x_valid)\n",
        "# x_test_vocab, x_test_vocab_len = get_vocab(x_test)\n",
        "vocabulary=list(tokenizer.word_index.keys())#get the vocabular\n",
        "vocabulary=len(vocabulary)+1#vocabsize\n",
        "# print(\"Numeric assignments, as you can see zero is reserved for padding\\n\",tokenizer.word_index,\"\\n\")\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX-abKaBkVQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform(tmp):\n",
        "  train_seqs = tokenizer.texts_to_sequences([tmp])\n",
        "  padded_seqs = pad_sequences(train_seqs, padding='post', maxlen=20)\n",
        "  res = padded_seqs[0]\n",
        "  return np.array(res)\n",
        "def transform_data(tmp):\n",
        "  res = []\n",
        "  for p in tmp:\n",
        "    res += [(transform(p[0]), transform(p[1]))]\n",
        "  return res\n",
        "x_train_seqs = transform_data(x_train)\n",
        "x_test_seqs = transform_data(x_test)\n",
        "x_valid_seqs = transform_data(x_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4--Z2YZpT_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def separate(tmp):\n",
        "  a = np.array([x[0] for x in tmp], dtype=np.uint8)\n",
        "  b = np.array([x[1] for x in tmp])\n",
        "  return a, b\n",
        "\n",
        "x_train_seqs_1, x_train_seqs_2 = separate(x_train_seqs)\n",
        "x_test_seqs_1, x_test_seqs_2 = separate(x_test_seqs)\n",
        "x_valid_seqs_1, x_valid_seqs_2 = separate(x_valid_seqs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE72D66I94Xn",
        "colab_type": "code",
        "outputId": "5d0a8113-9cd7-4c5b-f89c-f5c15b750d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(x_train_seqs_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 786    4 3522 ... 8967    9    8]\n",
            " [3525  955  370 ...    0    0    0]\n",
            " [  63 1013 1229 ...  248    8    0]\n",
            " ...\n",
            " [   9  705   95 ...   59 2121    3]\n",
            " [   4 1028   62 ...  148  249   34]\n",
            " [3539   67  682 ...    8    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-oQAyJ2HzGN",
        "colab_type": "text"
      },
      "source": [
        "Create the model in the cell below:\n",
        "Try out different sizes for LSTM 50,100,300 and use relu activations. Also report results with Bi-LSTM as well.<br>\n",
        "<i>To boost performance you can try adding a hidden layer between the lstm and output layer and also by adding a dropout layer in between different layers</i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djpj5YxDx1ib",
        "colab_type": "code",
        "outputId": "1ab797b3-83fb-4101-c529-cd4d314e1f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load pretrained embeddings\n",
        "EMBEDDING_DIM = 50\n",
        "embeddings_index = {}\n",
        "with open(\"glove.6B.50d.txt\") as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "print(embedding_matrix.shape)\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # words not found in embedding index will be all-zeros.\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12491, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FZi3ZMgHzGO",
        "colab_type": "code",
        "outputId": "1dff8f03-f441-4918-efb9-a78e44ad0399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# code model here\n",
        "inputs1 = Input(shape=(20,))\n",
        "inputs2 = Input(shape=(20,))\n",
        "shared_emb = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=20, trainable=False)\n",
        "emb_1 = shared_emb(inputs1)\n",
        "emb_2 = shared_emb(inputs2)\n",
        "\n",
        "shared_lstm = LSTM(300, activation='relu')\n",
        "lstm_1 = shared_lstm(emb_1)\n",
        "lstm_2 = shared_lstm(emb_2)\n",
        "\n",
        "merged = tf.keras.layers.concatenate([lstm_1, lstm_2])\n",
        "output = Dense(2, activation='softmax')(merged)\n",
        "\n",
        "model = Model(inputs=[inputs1, inputs2], outputs=output)\n",
        "model.compile(loss=[\"categorical_crossentropy\"], optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_18 (InputLayer)           [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_19 (InputLayer)           [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_14 (Embedding)        (None, 20, 50)       624550      input_18[0][0]                   \n",
            "                                                                 input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_12 (LSTM)                  (None, 300)          421200      embedding_14[0][0]               \n",
            "                                                                 embedding_14[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 600)          0           lstm_12[0][0]                    \n",
            "                                                                 lstm_12[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 2)            1202        concatenate_3[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,046,952\n",
            "Trainable params: 422,402\n",
            "Non-trainable params: 624,550\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eChc7f86HzGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "filepath = \"setting_\" + \"model1\" + \".hdf5\"\n",
        "logfilepath = \"setting_\"+\"model1\" + \".csv\"\n",
        "reduce_lr_rate=0.2\n",
        "logCallback = CSVLogger(logfilepath, separator=',', append=False)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=0, mode='auto')\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_weights_only=True, verbose=1,\n",
        "                             save_best_only=True, mode='auto')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_lr_rate, patience=10,\n",
        "                              cooldown=0, min_lr=0.0000000001, verbose=0)\n",
        "\n",
        "callbacks_list = [logCallback, earlyStopping, reduce_lr, checkpoint]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhBSM_yZHzGa",
        "colab_type": "code",
        "outputId": "f28dec72-a975-4ea1-cb80-a9f5c879959c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit([x_train_seqs_1, x_train_seqs_2],\n",
        "          y_train_enc, \n",
        "          # callbacks=callbacks_list, \n",
        "          validation_data=([x_valid_seqs_1, x_valid_seqs_2], y_valid_enc),\n",
        "          epochs=30, batch_size=32, verbose=1,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "115/115 [==============================] - 16s 139ms/step - loss: 0.6038 - accuracy: 0.6884 - val_loss: 0.6145 - val_accuracy: 0.6716\n",
            "Epoch 2/30\n",
            "115/115 [==============================] - 14s 124ms/step - loss: 0.5909 - accuracy: 0.6957 - val_loss: 0.6315 - val_accuracy: 0.6642\n",
            "Epoch 3/30\n",
            "115/115 [==============================] - 14s 125ms/step - loss: 0.5771 - accuracy: 0.7007 - val_loss: 0.6191 - val_accuracy: 0.6642\n",
            "Epoch 4/30\n",
            "115/115 [==============================] - 14s 124ms/step - loss: 0.6910 - accuracy: 0.7034 - val_loss: 0.6284 - val_accuracy: 0.6691\n",
            "Epoch 5/30\n",
            "115/115 [==============================] - 16s 135ms/step - loss: 0.5722 - accuracy: 0.7097 - val_loss: 0.6188 - val_accuracy: 0.6667\n",
            "Epoch 6/30\n",
            "115/115 [==============================] - 14s 125ms/step - loss: 0.5545 - accuracy: 0.7184 - val_loss: 0.6242 - val_accuracy: 0.6814\n",
            "Epoch 7/30\n",
            "115/115 [==============================] - 15s 131ms/step - loss: 1.2144 - accuracy: 0.7118 - val_loss: 0.6174 - val_accuracy: 0.6716\n",
            "Epoch 8/30\n",
            "115/115 [==============================] - 14s 123ms/step - loss: 0.5557 - accuracy: 0.7197 - val_loss: 0.6328 - val_accuracy: 0.6716\n",
            "Epoch 9/30\n",
            "115/115 [==============================] - 14s 125ms/step - loss: 0.5254 - accuracy: 0.7413 - val_loss: 0.6239 - val_accuracy: 0.6814\n",
            "Epoch 10/30\n",
            "115/115 [==============================] - 14s 123ms/step - loss: 0.4978 - accuracy: 0.7503 - val_loss: 0.6482 - val_accuracy: 0.6642\n",
            "Epoch 11/30\n",
            "115/115 [==============================] - 15s 129ms/step - loss: 0.4805 - accuracy: 0.7655 - val_loss: 0.6748 - val_accuracy: 0.6569\n",
            "Epoch 12/30\n",
            "115/115 [==============================] - 15s 134ms/step - loss: 0.4608 - accuracy: 0.7903 - val_loss: 0.6671 - val_accuracy: 0.6618\n",
            "Epoch 13/30\n",
            "115/115 [==============================] - 16s 137ms/step - loss: 0.4130 - accuracy: 0.8086 - val_loss: 0.7449 - val_accuracy: 0.6642\n",
            "Epoch 14/30\n",
            "115/115 [==============================] - 16s 140ms/step - loss: 0.3651 - accuracy: 0.8391 - val_loss: 0.8019 - val_accuracy: 0.6348\n",
            "Epoch 15/30\n",
            "115/115 [==============================] - 16s 137ms/step - loss: 0.3070 - accuracy: 0.8670 - val_loss: 0.8578 - val_accuracy: 0.6348\n",
            "Epoch 16/30\n",
            "115/115 [==============================] - 16s 135ms/step - loss: 0.3310 - accuracy: 0.8571 - val_loss: 0.9480 - val_accuracy: 0.6544\n",
            "Epoch 17/30\n",
            "115/115 [==============================] - 16s 137ms/step - loss: 0.2621 - accuracy: 0.8879 - val_loss: 0.9544 - val_accuracy: 0.6373\n",
            "Epoch 18/30\n",
            "115/115 [==============================] - 16s 138ms/step - loss: 0.2035 - accuracy: 0.9204 - val_loss: 1.0637 - val_accuracy: 0.6422\n",
            "Epoch 19/30\n",
            "115/115 [==============================] - 17s 148ms/step - loss: 0.1564 - accuracy: 0.9438 - val_loss: 1.1213 - val_accuracy: 0.6618\n",
            "Epoch 20/30\n",
            "115/115 [==============================] - 17s 150ms/step - loss: 0.1341 - accuracy: 0.9531 - val_loss: 1.2604 - val_accuracy: 0.6225\n",
            "Epoch 21/30\n",
            "115/115 [==============================] - 16s 138ms/step - loss: 0.1158 - accuracy: 0.9588 - val_loss: 1.1996 - val_accuracy: 0.6103\n",
            "Epoch 22/30\n",
            "115/115 [==============================] - 16s 139ms/step - loss: 0.0832 - accuracy: 0.9727 - val_loss: 1.2853 - val_accuracy: 0.6495\n",
            "Epoch 23/30\n",
            "115/115 [==============================] - 16s 138ms/step - loss: 0.0680 - accuracy: 0.9793 - val_loss: 1.6374 - val_accuracy: 0.6201\n",
            "Epoch 24/30\n",
            "115/115 [==============================] - 16s 141ms/step - loss: 0.0706 - accuracy: 0.9774 - val_loss: 1.2718 - val_accuracy: 0.6544\n",
            "Epoch 25/30\n",
            "115/115 [==============================] - 16s 135ms/step - loss: 0.0579 - accuracy: 0.9812 - val_loss: 1.5727 - val_accuracy: 0.6275\n",
            "Epoch 26/30\n",
            "115/115 [==============================] - 16s 140ms/step - loss: 0.0660 - accuracy: 0.9801 - val_loss: 1.3708 - val_accuracy: 0.6520\n",
            "Epoch 27/30\n",
            "115/115 [==============================] - 15s 132ms/step - loss: 0.0417 - accuracy: 0.9888 - val_loss: 1.7895 - val_accuracy: 0.6642\n",
            "Epoch 28/30\n",
            "115/115 [==============================] - 16s 137ms/step - loss: 0.0487 - accuracy: 0.9877 - val_loss: 1.7390 - val_accuracy: 0.6422\n",
            "Epoch 29/30\n",
            "115/115 [==============================] - 16s 141ms/step - loss: 0.0346 - accuracy: 0.9910 - val_loss: 1.8679 - val_accuracy: 0.6618\n",
            "Epoch 30/30\n",
            "115/115 [==============================] - 16s 139ms/step - loss: 0.0496 - accuracy: 0.9839 - val_loss: 1.8278 - val_accuracy: 0.6397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcb88c45b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUb7-MthHzGf",
        "colab_type": "text"
      },
      "source": [
        "Use the <b>model.predict</b> method to get predictions. There predictions will be a probability distribution over the lables, to get the desired class take the max value in a prediction vector as the predicted class.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJrLRPQ6I_24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxInd(x):\n",
        "  if x[0] > x[1]:\n",
        "    return 0\n",
        "  return 1\n",
        "def predict(data, model):\n",
        "  x_test_seqs = transform_data(data)\n",
        "  x_test_seqs_1, x_test_seqs_2 = separate(x_test_seqs)\n",
        "  res = model.predict([x_test_seqs_1, x_test_seqs_2])\n",
        "  res = [maxInd(x) for x in res]\n",
        "  print(res)\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPQTFAUpHzGg",
        "colab_type": "code",
        "outputId": "64138488-4303-44ec-9e9a-b4164dbd633c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "source": [
        "predictions = predict(x_test, model)\n",
        "labelList=[\"0\", \"1\"]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "test_Y = y_test_enc\n",
        "test_Y_max=np.argmax(test_Y, axis=-1)\n",
        "cm=confusion_matrix(test_Y_max,predictions)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "print(cm)\n",
        "cm = pd.DataFrame(cm, labelList,labelList )# matrix,names row,names col,\n",
        "# plt.figure(figsize=(10,7))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(cm, annot=True, annot_kws={\"size\": 11}, fmt=\".2f\") # font size\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1]\n",
            "[[0.37543253 0.62456747]\n",
            " [0.24498692 0.75501308]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc8gGQsEHzGk",
        "colab_type": "code",
        "outputId": "7a1eea9a-9c35-498f-d134-bbc8f19dcca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(\"Classification Report\\n\",classification_report(test_Y_max, predictions, labels=[0,1], target_names = labelList, zero_division=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.38      0.40       578\n",
            "           1       0.71      0.76      0.73      1147\n",
            "\n",
            "    accuracy                           0.63      1725\n",
            "   macro avg       0.57      0.57      0.57      1725\n",
            "weighted avg       0.62      0.63      0.62      1725\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhBkQgmUZd-i",
        "colab_type": "text"
      },
      "source": [
        "# Model with BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAWX_Vm_WKXD",
        "colab_type": "code",
        "outputId": "c04af72f-2b1b-4406-84e0-9e67e2d3a603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "inputs1 = Input(shape=(20,))\n",
        "inputs2 = Input(shape=(20,))\n",
        "shared_emb = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=20, trainable=False)\n",
        "emb_1 = shared_emb(inputs1)\n",
        "emb_2 = shared_emb(inputs2)\n",
        "\n",
        "shared_lstm = Bidirectional(LSTM(300, activation='relu'))\n",
        "lstm_1 = shared_lstm(emb_1)\n",
        "lstm_2 = shared_lstm(emb_2)\n",
        "\n",
        "merged = tf.keras.layers.concatenate([lstm_1, lstm_2])\n",
        "output = Dense(2, activation='softmax')(merged)\n",
        "\n",
        "model = Model(inputs=[inputs1, inputs2], outputs=output)\n",
        "model.compile(loss=[\"categorical_crossentropy\"], optimizer='adam', metrics=['accuracy'])\n",
        "# model.summary()\n",
        "\n",
        "model.fit([x_train_seqs_1, x_train_seqs_2],\n",
        "          y_train_enc, \n",
        "          # callbacks=callbacks_list, \n",
        "          validation_data=([x_valid_seqs_1, x_valid_seqs_2], y_valid_enc),\n",
        "          epochs=20, batch_size=32, verbose=1,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "115/115 [==============================] - 30s 262ms/step - loss: 0.6031 - accuracy: 0.6854 - val_loss: 0.6222 - val_accuracy: 0.6618\n",
            "Epoch 2/20\n",
            "115/115 [==============================] - 30s 261ms/step - loss: 0.5805 - accuracy: 0.7061 - val_loss: 0.6208 - val_accuracy: 0.6691\n",
            "Epoch 3/20\n",
            "115/115 [==============================] - 30s 257ms/step - loss: 0.5735 - accuracy: 0.7208 - val_loss: 0.6082 - val_accuracy: 0.6789\n",
            "Epoch 4/20\n",
            "115/115 [==============================] - 30s 259ms/step - loss: 0.5534 - accuracy: 0.7293 - val_loss: 0.6030 - val_accuracy: 0.6838\n",
            "Epoch 5/20\n",
            "115/115 [==============================] - 29s 254ms/step - loss: 0.5191 - accuracy: 0.7410 - val_loss: 0.6262 - val_accuracy: 0.6789\n",
            "Epoch 6/20\n",
            "115/115 [==============================] - 30s 259ms/step - loss: 0.4985 - accuracy: 0.7628 - val_loss: 0.6093 - val_accuracy: 0.6789\n",
            "Epoch 7/20\n",
            "115/115 [==============================] - 30s 265ms/step - loss: 0.4683 - accuracy: 0.7822 - val_loss: 0.7893 - val_accuracy: 0.6912\n",
            "Epoch 8/20\n",
            "115/115 [==============================] - 30s 260ms/step - loss: 0.4363 - accuracy: 0.8053 - val_loss: 0.6139 - val_accuracy: 0.6740\n",
            "Epoch 9/20\n",
            "115/115 [==============================] - 30s 264ms/step - loss: 0.3864 - accuracy: 0.8402 - val_loss: 0.6514 - val_accuracy: 0.6716\n",
            "Epoch 10/20\n",
            "115/115 [==============================] - 30s 261ms/step - loss: 0.3275 - accuracy: 0.8580 - val_loss: 0.7538 - val_accuracy: 0.6667\n",
            "Epoch 11/20\n",
            "115/115 [==============================] - 30s 264ms/step - loss: 0.2505 - accuracy: 0.8991 - val_loss: 1.0850 - val_accuracy: 0.6789\n",
            "Epoch 12/20\n",
            "115/115 [==============================] - 30s 262ms/step - loss: 0.1863 - accuracy: 0.9370 - val_loss: 0.9547 - val_accuracy: 0.6642\n",
            "Epoch 13/20\n",
            "115/115 [==============================] - 29s 255ms/step - loss: 0.1566 - accuracy: 0.9460 - val_loss: 1.2260 - val_accuracy: 0.6716\n",
            "Epoch 14/20\n",
            "115/115 [==============================] - 32s 280ms/step - loss: 0.1051 - accuracy: 0.9700 - val_loss: 1.2374 - val_accuracy: 0.6618\n",
            "Epoch 15/20\n",
            "115/115 [==============================] - 30s 257ms/step - loss: 0.0811 - accuracy: 0.9793 - val_loss: 1.3300 - val_accuracy: 0.6691\n",
            "Epoch 16/20\n",
            "115/115 [==============================] - 30s 259ms/step - loss: 0.0879 - accuracy: 0.9757 - val_loss: 1.2853 - val_accuracy: 0.6495\n",
            "Epoch 17/20\n",
            "115/115 [==============================] - 30s 263ms/step - loss: 0.0613 - accuracy: 0.9842 - val_loss: 1.2546 - val_accuracy: 0.6422\n",
            "Epoch 18/20\n",
            "115/115 [==============================] - 30s 260ms/step - loss: 0.0444 - accuracy: 0.9888 - val_loss: 1.2865 - val_accuracy: 0.6569\n",
            "Epoch 19/20\n",
            "115/115 [==============================] - 30s 258ms/step - loss: 0.0484 - accuracy: 0.9877 - val_loss: 1.2467 - val_accuracy: 0.6569\n",
            "Epoch 20/20\n",
            "115/115 [==============================] - 30s 263ms/step - loss: 0.0468 - accuracy: 0.9902 - val_loss: 1.4383 - val_accuracy: 0.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcb9d4dbeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyqmQ64DaI57",
        "colab_type": "code",
        "outputId": "01b7310f-c9c5-43f9-8ccc-670f3e7a76c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "predictions = predict(x_test, model)\n",
        "labelList=[\"0\", \"1\"]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "test_Y = y_test_enc\n",
        "test_Y_max=np.argmax(test_Y, axis=-1)\n",
        "cm=confusion_matrix(test_Y_max,predictions)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "print(cm)\n",
        "cm = pd.DataFrame(cm, labelList,labelList )# matrix,names row,names col,\n",
        "# plt.figure(figsize=(10,7))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(cm, annot=True, annot_kws={\"size\": 11}, fmt=\".2f\") # font size\n",
        "plt.show()\n",
        "\n",
        "print(\"Classification Report\\n\",classification_report(test_Y_max, predictions, labels=[0,1], target_names = labelList, zero_division=0))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
            "[[0.36678201 0.63321799]\n",
            " [0.23975588 0.76024412]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.37      0.40       578\n",
            "           1       0.70      0.76      0.73      1147\n",
            "\n",
            "    accuracy                           0.63      1725\n",
            "   macro avg       0.57      0.56      0.56      1725\n",
            "weighted avg       0.61      0.63      0.62      1725\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-vGIXH9HzGs",
        "colab_type": "text"
      },
      "source": [
        "# Task 2 Sentiment Classification\n",
        "For this task we will be reusing the movie reviews dataset available on <a href=\"https://www.kaggle.com/c/word2vec-nlp-tutorial/data\">kaggle</a> and download the dataset from there. \n",
        "We will be using the unlabeledTrainData file and labeledTrainData file. We will use the gensim package to train word2vec embeddings using [gensim](https://radimrehurek.com/gensim/) package and unlabelled train data as in the previous assignmnet. Now instead for creating a single representation for each review we will be using deep learning models for this task. We will use the same archetecture as before but will experiment with different reccurant networks namely RNN, GRU and LSTM.<br> This task might feel like <a href=\"https://ibb.co/Tgh2XyH\">this</a> but since this is a deep learning assignment thus we must use it.\n",
        "<h3>Data Preperation</h3>\n",
        "<ul>\n",
        "    <li> First we need to preprocess the data, convert the data to lower casing(both files). Any other preprocessing procedures are optional but keep in mind that this will affect the performance of your model.</li>\n",
        "    <li> Split the labeledTrainData data file into test, train and validation in the ratio 20,70,10. Use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">scikit_test_train_split</a> <br><i><b>Hint:</b> use the splitter twice to get desired data splits.</i></li>\n",
        "    <li> Next we need the vocabulary, vocabulary size and to convert sentences to numeric sequences by representing each word with a numeric value which will make our implementation easier later on, use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\">Tokenizer</a> from keras. <br><i>(Fit the tokenizer on train data and use the same tokenizer to convert train,test and validation data to numeric sequences)</i> </li>\n",
        "    <li>  Use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\"> pad sequences</a> to add post padding to all sentences that are shorter than maximum sequence length</li>\n",
        "    <li> Use one hot representation for targets/labels, you can use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">scikit learn</a> or <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing\">keras preprocessing</a>.</li>\n",
        "</ul>\n",
        "<h3>Loading embeddings</h3>\n",
        "<ul>\n",
        "    <li> As state before use the gensim package to train the word2vec model on unlabelledTrainData file</li>\n",
        "    <li> Next we will create a dictionary for our dataset's vocabulary. Copy all the word embeddings for words that are in our vocabulary and in the word2vec model, if a word exists in our vocabulary but does not exist in word2vec model create a zero vector of embedding dimension size and add it to the dictionary.</li>\n",
        "</ul>\n",
        "<h3>Create Model</h3>\n",
        "<ul>\n",
        "    <li> Here is a visual for the model <img src=\"sentimentdeep.png\">\n",
        "    <li> Create the model using <a href\"https://www.tensorflow.org/guide/keras/functional\">functional API</a> or the <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\">Sequential API</a></li>\n",
        "    <li> Hints: The emebedding layer has a parameter that allows you to use pretrained embeddings</li>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99MklsScHzGt",
        "colab_type": "text"
      },
      "source": [
        "Use can reuse the code snippets from above for call backs, prediction heat map and classification report\n",
        "<i>You will have provide a label list for this specific dataset inorder for them to run, you are to make the required changes yourself</i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdEyeu1NHzGu",
        "colab_type": "code",
        "outputId": "d4eed361-ad3d-436a-f645-a69f54c7772d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# !unzip \"/content/drive/My Drive/Colab Notebooks/labeledTrainData.tsv.zip\"\n",
        "# !unzip \"/content/drive/My Drive/Colab Notebooks/unlabeledTrainData.tsv.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Colab Notebooks/labeledTrainData.tsv.zip\n",
            "  inflating: labeledTrainData.tsv    \n",
            "Archive:  /content/drive/My Drive/Colab Notebooks/unlabeledTrainData.tsv.zip\n",
            "  inflating: unlabeledTrainData.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb16wLD7HzG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def preprocess(tweet):\n",
        "    processed_data = tweet.lower()\n",
        "    processed_data = re.sub(\"@[\\S]+\", \"AT_TOKEN\", processed_data)\n",
        "    processed_data = re.sub(\"[#]\", \"\", processed_data)\n",
        "    processed_data = re.sub(\"<.*>\", \"\", processed_data)\n",
        "    processed_data = re.sub(\"[^a-zA-Z0-9\\s_]\", \" \", processed_data)\n",
        "    processed_data = re.sub(\"[\\s]+\", \" \", processed_data)\n",
        "    processed_data = re.sub(\"[_]{2,10}\", \"\", processed_data)\n",
        "    processed_data = processed_data.split(\" \")\n",
        "    return [x for x in processed_data if len(x) > 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh0hZ48GHzGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
        "unlabaled_reviews = [preprocess(x) for x in data['review']]\n",
        "\n",
        "data = pd.read_csv(\"labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
        "X = [preprocess(x) for x in data['review']]\n",
        "Y = [str(x) for x in data['sentiment']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAlz9S_DeWVj",
        "colab_type": "code",
        "outputId": "c797a0fd-d50f-4367-f94d-d7840a19d516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_distribution(data):\n",
        "  dist = {}\n",
        "  for point in data:\n",
        "    for token in point:\n",
        "      if token in dist:\n",
        "        dist[token] += 1\n",
        "      else: dist[token] = 1\n",
        "  return dist\n",
        "def handle_unks(data):\n",
        "  dist = get_distribution(data)\n",
        "  print(len(dist))\n",
        "  for i, point in enumerate(data):\n",
        "    for j, token in enumerate(point):\n",
        "      if dist[token] == 1:\n",
        "        data[i][j] = 'UNK'\n",
        "  return data\n",
        "\n",
        "unlabaled_reviews = handle_unks(unlabaled_reviews)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyDuNXMppeAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.125, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPlhmIDgeWSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "def trainWord2Vec(data):\n",
        "  \"\"\"\n",
        "  Return preprocessed data\n",
        "\n",
        "  Args:\n",
        "      data : movie reviews\n",
        "\n",
        "  Returns: model\n",
        "  model : Word2Vec model \n",
        "  \"\"\"\n",
        "  emb_len = 300\n",
        "  model = gensim.models.Word2Vec(sentences=data, size = emb_len, window=2, min_count=1)\n",
        "  return model\n",
        "w2v_model = trainWord2Vec(unlabaled_reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VDtekcKhquO",
        "colab_type": "code",
        "outputId": "7007fa58-84d9-44da-b6d6-23801dfd2150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#making a dictionary\n",
        "embeddings_dictionary = {}\n",
        "for review in unlabaled_reviews:\n",
        "  for word in review:\n",
        "    if word not in embeddings_dictionary:\n",
        "      if word in w2v_model.wv:\n",
        "        embeddings_dictionary[word] = w2v_model.wv[word]\n",
        "      else:\n",
        "        embeddings_dictionary[word] = [0]*300\n",
        "print(len(embeddings_dictionary))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgbRYKdDhq0N",
        "colab_type": "code",
        "outputId": "a0edca87-d3c7-444d-e170-6898e8d120f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"<unk>\", filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "#load pretrained embeddings\n",
        "EMBEDDING_DIM = 300\n",
        "embeddings_index = embeddings_dictionary\n",
        "\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "print(embedding_matrix.shape)\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # words not found in embedding index will be all-zeros.\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50733, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt2XclTnk-wY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform(tmp):\n",
        "  train_seqs = tokenizer.texts_to_sequences([tmp])\n",
        "  padded_seqs = pad_sequences(train_seqs, padding='post', maxlen=20)\n",
        "  res = padded_seqs[0]\n",
        "  return res\n",
        "def transform_data(tmp):\n",
        "  res = []\n",
        "  for p in tmp:\n",
        "    res += [transform(p)]\n",
        "  return res\n",
        "x_train_seqs = np.array(transform_data(x_train))\n",
        "x_test_seqs = np.array(transform_data(x_test))\n",
        "x_valid_seqs = np.array(transform_data(x_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbtHUGeI2tjN",
        "colab_type": "code",
        "outputId": "8e24bfe0-c1d5-4254-aae2-da94d5077d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_train_seqs.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17500, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvZoYXDHsFIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encod = {\n",
        "    \"1\": [0, 1],\n",
        "    \"0\": [1, 0]\n",
        "}\n",
        "y_train_enc = np.array([encod[x] for x in y_train], dtype=np.uint8)\n",
        "y_valid_enc = np.array([encod[x] for x in y_valid], dtype=np.uint8)\n",
        "y_test_enc = np.array([encod[x] for x in y_test], dtype=np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5eDCTtW5VhG",
        "colab_type": "code",
        "outputId": "b8138a96-5cd0-4137-ddc5-f0adedd375d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_test_enc.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WktiU41thAZ",
        "colab_type": "code",
        "outputId": "b2d8e614-9546-4d9f-cad7-1b9999608bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def make_model(rec_layer):\n",
        "  inputs1 = Input(shape=(20,))\n",
        "  emb = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=20, trainable=False)\n",
        "  emb_1 = emb(inputs1)\n",
        "\n",
        "  # lstm = LSTM(300, activation='relu')\n",
        "  # lstm_1 = lstm(emb_1)\n",
        "  recurrent_layer = rec_layer(emb_1)\n",
        "\n",
        "  output = Dense(2, activation='softmax')(recurrent_layer)\n",
        "\n",
        "  model = Model(inputs=inputs1, outputs=output)\n",
        "  model.compile(loss=[\"categorical_crossentropy\"], optimizer='adam', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  model.fit(x_train_seqs,\n",
        "            y_train_enc, \n",
        "            # callbacks=callbacks_list, \n",
        "            validation_data=(x_valid_seqs, y_valid_enc),\n",
        "            epochs=10, batch_size=32, verbose=1,shuffle=True)\n",
        "  return model\n",
        "\n",
        "lstm_model = make_model(LSTM(100, activation='relu'))\n",
        "gru_model = make_model(GRU(100, activation='relu'))\n",
        "rnn_model = make_model(SimpleRNN(100, activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_26 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_18 (Embedding)     (None, 20, 300)           15219900  \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 15,380,502\n",
            "Trainable params: 160,602\n",
            "Non-trainable params: 15,219,900\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "547/547 [==============================] - 16s 29ms/step - loss: 0.5555 - accuracy: 0.7051 - val_loss: 0.5190 - val_accuracy: 0.7336\n",
            "Epoch 2/10\n",
            "547/547 [==============================] - 16s 29ms/step - loss: 0.4999 - accuracy: 0.7495 - val_loss: 0.5009 - val_accuracy: 0.7464\n",
            "Epoch 3/10\n",
            "547/547 [==============================] - 16s 29ms/step - loss: 0.4648 - accuracy: 0.7706 - val_loss: 0.4876 - val_accuracy: 0.7504\n",
            "Epoch 4/10\n",
            "547/547 [==============================] - 15s 28ms/step - loss: 0.4313 - accuracy: 0.7897 - val_loss: 0.4858 - val_accuracy: 0.7544\n",
            "Epoch 5/10\n",
            "547/547 [==============================] - 15s 28ms/step - loss: 0.3869 - accuracy: 0.8180 - val_loss: 0.5028 - val_accuracy: 0.7468\n",
            "Epoch 6/10\n",
            "547/547 [==============================] - 16s 29ms/step - loss: 0.3403 - accuracy: 0.8435 - val_loss: 0.5421 - val_accuracy: 0.7380\n",
            "Epoch 7/10\n",
            "547/547 [==============================] - 16s 29ms/step - loss: 0.2794 - accuracy: 0.8765 - val_loss: 0.6012 - val_accuracy: 0.7372\n",
            "Epoch 8/10\n",
            "547/547 [==============================] - 16s 28ms/step - loss: 0.2281 - accuracy: 0.9040 - val_loss: 0.6681 - val_accuracy: 0.7396\n",
            "Epoch 9/10\n",
            "547/547 [==============================] - 16s 29ms/step - loss: 0.1724 - accuracy: 0.9307 - val_loss: 0.8134 - val_accuracy: 0.7272\n",
            "Epoch 10/10\n",
            "547/547 [==============================] - 16s 29ms/step - loss: 0.1222 - accuracy: 0.9522 - val_loss: 0.9663 - val_accuracy: 0.7272\n",
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_27 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_19 (Embedding)     (None, 20, 300)           15219900  \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 100)               120600    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 15,340,702\n",
            "Trainable params: 120,802\n",
            "Non-trainable params: 15,219,900\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 0.5509 - accuracy: 0.7067 - val_loss: 0.5071 - val_accuracy: 0.7332\n",
            "Epoch 2/10\n",
            "547/547 [==============================] - 13s 23ms/step - loss: 0.4869 - accuracy: 0.7559 - val_loss: 0.4869 - val_accuracy: 0.7476\n",
            "Epoch 3/10\n",
            "547/547 [==============================] - 13s 23ms/step - loss: 0.4516 - accuracy: 0.7805 - val_loss: 0.4806 - val_accuracy: 0.7592\n",
            "Epoch 4/10\n",
            "547/547 [==============================] - 13s 23ms/step - loss: 0.4167 - accuracy: 0.7990 - val_loss: 0.4760 - val_accuracy: 0.7568\n",
            "Epoch 5/10\n",
            "547/547 [==============================] - 13s 23ms/step - loss: 0.3757 - accuracy: 0.8233 - val_loss: 0.4944 - val_accuracy: 0.7572\n",
            "Epoch 6/10\n",
            "547/547 [==============================] - 13s 23ms/step - loss: 0.3249 - accuracy: 0.8521 - val_loss: 0.5235 - val_accuracy: 0.7612\n",
            "Epoch 7/10\n",
            "547/547 [==============================] - 13s 23ms/step - loss: 0.2642 - accuracy: 0.8840 - val_loss: 0.6483 - val_accuracy: 0.7336\n",
            "Epoch 8/10\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 0.2090 - accuracy: 0.9145 - val_loss: 0.6813 - val_accuracy: 0.7492\n",
            "Epoch 9/10\n",
            "547/547 [==============================] - 13s 23ms/step - loss: 0.1508 - accuracy: 0.9420 - val_loss: 0.7940 - val_accuracy: 0.7512\n",
            "Epoch 10/10\n",
            "547/547 [==============================] - 13s 23ms/step - loss: 0.1089 - accuracy: 0.9574 - val_loss: 0.8485 - val_accuracy: 0.7476\n",
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_28 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_20 (Embedding)     (None, 20, 300)           15219900  \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 100)               40100     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 15,260,202\n",
            "Trainable params: 40,302\n",
            "Non-trainable params: 15,219,900\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 0.6135 - accuracy: 0.6614 - val_loss: 0.5404 - val_accuracy: 0.7160\n",
            "Epoch 2/10\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 0.5283 - accuracy: 0.7296 - val_loss: 0.5249 - val_accuracy: 0.7248\n",
            "Epoch 3/10\n",
            "547/547 [==============================] - 5s 8ms/step - loss: 0.5016 - accuracy: 0.7473 - val_loss: 0.5288 - val_accuracy: 0.7180\n",
            "Epoch 4/10\n",
            "547/547 [==============================] - 5s 8ms/step - loss: 0.4823 - accuracy: 0.7623 - val_loss: 0.5070 - val_accuracy: 0.7520\n",
            "Epoch 5/10\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 0.4599 - accuracy: 0.7797 - val_loss: 0.5749 - val_accuracy: 0.7036\n",
            "Epoch 6/10\n",
            "547/547 [==============================] - 5s 8ms/step - loss: 0.4332 - accuracy: 0.7957 - val_loss: 0.5286 - val_accuracy: 0.7532\n",
            "Epoch 7/10\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 0.4021 - accuracy: 0.8160 - val_loss: 0.5511 - val_accuracy: 0.7264\n",
            "Epoch 8/10\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 0.3767 - accuracy: 0.8287 - val_loss: 0.5606 - val_accuracy: 0.7364\n",
            "Epoch 9/10\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 0.3541 - accuracy: 0.8433 - val_loss: 0.5877 - val_accuracy: 0.7268\n",
            "Epoch 10/10\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 0.3258 - accuracy: 0.8551 - val_loss: 0.5956 - val_accuracy: 0.7148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rom30Vr4thLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxInd(x):\n",
        "  if x[0] > x[1]:\n",
        "    return 0\n",
        "  return 1\n",
        "def predict(data, inp_model):\n",
        "  x_test_seqs = np.array(transform_data(data))\n",
        "  print(x_test_seqs.shape)\n",
        "  res = inp_model.predict(x_test_seqs)\n",
        "  res = [maxInd(x) for x in res]\n",
        "  print(np.array(res).shape)\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIa1P8I2thJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report(inp_model):\n",
        "  predictions = predict(x_test, inp_model)\n",
        "  labelList=[\"0\", \"1\"]\n",
        "\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  test_Y = y_test_enc\n",
        "  test_Y_max=np.argmax(test_Y, axis=-1)\n",
        "  cm=confusion_matrix(test_Y_max,predictions)\n",
        "  cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "  print(cm)\n",
        "  cm = pd.DataFrame(cm, labelList,labelList )# matrix,names row,names col,\n",
        "  # plt.figure(figsize=(10,7))\n",
        "  sn.set(font_scale=1.4) # for label size\n",
        "  sn.heatmap(cm, annot=True, annot_kws={\"size\": 11}, fmt=\".2f\") # font size\n",
        "  plt.show()\n",
        "  print(\"Classification Report\\n\",classification_report(test_Y_max, predictions, labels=[0,1], target_names = labelList, zero_division=0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK-w3H7uthHf",
        "colab_type": "code",
        "outputId": "cce5c6f3-6fd4-48c8-9fe5-1ddd4d3b84c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "print(\"For RNN\")\n",
        "report(rnn_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For RNN\n",
            "(5000, 20)\n",
            "(5000,)\n",
            "[[0.70839874 0.29160126]\n",
            " [0.26264274 0.73735726]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.71      0.72      2548\n",
            "           1       0.71      0.74      0.72      2452\n",
            "\n",
            "    accuracy                           0.72      5000\n",
            "   macro avg       0.72      0.72      0.72      5000\n",
            "weighted avg       0.72      0.72      0.72      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU0SzDfN4Kl6",
        "colab_type": "code",
        "outputId": "a25d2379-11db-4ee9-f552-6f573fccbea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "print(\"For LSTM\")\n",
        "report(lstm_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For LSTM\n",
            "(5000, 20)\n",
            "(5000,)\n",
            "[[0.67582418 0.32417582]\n",
            " [0.22634584 0.77365416]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.68      0.71      2548\n",
            "           1       0.70      0.77      0.73      2452\n",
            "\n",
            "    accuracy                           0.72      5000\n",
            "   macro avg       0.73      0.72      0.72      5000\n",
            "weighted avg       0.73      0.72      0.72      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eugnGlI14Oa9",
        "colab_type": "code",
        "outputId": "244d252d-5b52-414f-d934-9fc0ed895537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "print(\"For GRU\")\n",
        "report(gru_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For GRU\n",
            "(5000, 20)\n",
            "(5000,)\n",
            "[[0.76255887 0.23744113]\n",
            " [0.27732463 0.72267537]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.76      0.75      2548\n",
            "           1       0.75      0.72      0.73      2452\n",
            "\n",
            "    accuracy                           0.74      5000\n",
            "   macro avg       0.74      0.74      0.74      5000\n",
            "weighted avg       0.74      0.74      0.74      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RsMMu7YHzG-",
        "colab_type": "text"
      },
      "source": [
        "# We hope all of you are working on your projects and <a href=\"https://ibb.co/dcpf4vS\"> Kudos for completing the assingnment</a>"
      ]
    }
  ]
}